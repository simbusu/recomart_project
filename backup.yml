version: '3.8'

x-airflow-common: &airflow-common
  image: apache/airflow:2.7.1
  environment: &airflow-common-env
    AIRFLOW__CORE__EXECUTOR: LocalExecutor
    AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
    AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
    AIRFLOW__WEBSERVER__SECRET_KEY: 'recomart_super_secret_key'
    AIRFLOW__CORE__HOSTNAME_CALLABLE: 'airflow.utils.net.get_host_ip_address'
    AIRFLOW__CORE__FERNET_KEY: 'recomart_project_fernet_key_example_32chars='
    PYTHONPATH: /opt/airflow:/opt/airflow/dags:/opt/airflow/plugins
    NLTK_DATA: /opt/airflow/nltk_data
  volumes:
    - ./dags:/opt/airflow/dags
    - ./scripts:/opt/airflow/scripts
    - ./ingester.py:/opt/airflow/ingester.py
    - ./init_db.py:/opt/airflow/init_db.py
    - ./nltk_data:/opt/airflow/nltk_data
    - ./users.csv:/opt/airflow/users.csv
    - ./products.csv:/opt/airflow/products.csv
    - ./data_lake:/opt/airflow/data_lake
    - ./models:/opt/airflow/models
    - ./logs:/opt/airflow/logs
    - ./plugins:/opt/airflow/plugins
  extra_hosts:
    - "host.docker.internal:host-gateway"

services:
  postgres:
    image: postgres:13
    container_name: postgres
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    ports: [ "5432:5432" ]
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "airflow"]
      interval: 5s
      retries: 5
    restart: always

  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
    restart: always

  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: kafka
    depends_on: [ zookeeper ]
    ports: [ "9092:9092" ]
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092,PLAINTEXT_INTERNAL://kafka:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT_INTERNAL
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    restart: always

  airflow-init:
    <<: *airflow-common
    container_name: recomart-airflow-init
    user: "0:0"
    command: >
      bash -c "
      apt-get update && apt-get install -y build-essential python3-dev &&
      su -s /bin/bash airflow -c '
        mkdir -p /opt/airflow/nltk_data /opt/airflow/models /opt/airflow/logs /opt/airflow/plugins
        
        # 1. Uninstall any broken versions first
        pip uninstall -y scikit-surprise Cython numpy
        
        # 2. Install the EXACT legacy build tools needed for this library
        pip install --no-cache-dir numpy==1.24.3 Cython==0.29.36
        
        # 3. Install surprise using the current environment tools (Bypassing build isolation)
        pip install --no-cache-dir --no-build-isolation scikit-surprise==1.1.4
        
        # 4. Install everything else
        pip install --no-cache-dir pandas requests sqlalchemy psycopg2-binary nltk scikit-learn
        
        python -m nltk.downloader -d /opt/airflow/nltk_data vader_lexicon
        airflow db init
        python /opt/airflow/init_db.py
        airflow users create --username airflow --firstname admin --lastname admin --role Admin --email admin@recomart.com --password airflow || true
      '"
    depends_on:
      postgres:
        condition: service_healthy

  airflow-webserver:
    <<: *airflow-common
    container_name: airflow-webserver
    user: "${AIRFLOW_UID:-50000}:0"
    environment:
      <<: *airflow-common-env
      _PIP_ADDITIONAL_REQUIREMENTS: "pandas requests sqlalchemy psycopg2-binary nltk scikit-learn scikit-surprise"
    command: webserver
    ports: [ "8080:8080" ]
    depends_on:
      airflow-init:
        condition: service_completed_successfully
    restart: always

  airflow-scheduler:
    <<: *airflow-common
    container_name: airflow-scheduler
    user: "${AIRFLOW_UID:-50000}:0"
    environment:
      <<: *airflow-common-env
      _PIP_ADDITIONAL_REQUIREMENTS: "pandas requests sqlalchemy psycopg2-binary nltk scikit-learn scikit-surprise"
    command: scheduler
    depends_on:
      airflow-init:
        condition: service_completed_successfully
    restart: always
